exp_name: supervised_random_search_toy
experiment: pydgn.experiment.supervised_task.SupervisedTask
higher_results_are_better: True
log_every: 1
dataset_getter: pydgn.data.provider.DataProvider
data_loader:
  class_name: torch_geometric.loader.DataLoader
  args:
    num_workers : 0  # > 0 only with --debug option and GPU device
    pin_memory: False  # True only with --debug option and GPU device
device: cpu
seed: 42
num_samples: 7  # number of random searches to try
random:
  supervised_config:
    model: pydgn.model.dgn.toy_dgn.ToyDGN
    checkpoint: True
    batch_size:
      sample_method: pydgn.evaluation.util.choice
      args:
        - 32
        - 64
        - 128
    epochs: 5
    dim_embedding: 4
    num_layers:
      sample_method: pydgn.evaluation.util.randint
      args:
        - 1  # min
        - 5  # max
    aggregation: mean
    optimizer:
      sample_method: pydgn.evaluation.util.choice
      args:
        - class_name: pydgn.training.callback.optimizer.Optimizer
          args:
            optimizer_class_name: torch.optim.Adam
            lr:
              sample_method: pydgn.evaluation.util.normal
              args:
                - 0.001
                - 0.0001
            weight_decay: 0.
        - class_name: pydgn.training.callback.optimizer.Optimizer
          args:
            optimizer_class_name: torch.optim.Adamax
            lr:
              sample_method: pydgn.evaluation.util.loguniform
              args:
                - 0.0001
                - 0.01
            weight_decay: 0.
    scheduler: null
    loss: pydgn.training.callback.metric.MulticlassClassification
    scorer:
      class_name: pydgn.training.callback.metric.MulticlassAccuracy
    readout: pydgn.model.readout.graph_readout.LinearGraphReadout
    engine: pydgn.training.engine.TrainingEngine
    l2: 0.
    gradient_clipper: null
    dropout: 0.
    early_stopper:
      class_name: pydgn.training.callback.early_stopping.PatienceEarlyStopper
      args:
        patience: 3
        monitor: validation_main_score # (train_,validation_)[name_of_the_scorer_or_loss_to_monitor] -> we can use MAIN_LOSS or MAIN_SCORE
        mode: max
        checkpoint: True
    plotter: pydgn.training.callback.plotter.Plotter
    shuffle: True
